{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import umap\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hypertools as hyp\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from util import evaluate_model_performance, evaluate_model_fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(os.getcwd()).parent.parent / \"data\" / \"dataset_diabetes\"\n",
    "df = pd.read_csv(data_path / \"diabetic_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"] = df[\"age_all\"]\n",
    "\n",
    "columns_to_remove = ['encounter_id', 'patient_nbr', 'readmitted', 'readmit_binary', 'diabetes_type', \\\n",
    "    'had_emergency', 'had_inpatient_days', 'had_outpatient_days', 'race_all', 'age_all']\n",
    "\n",
    "df_for_experimenting = df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_write = Path(os.getcwd()).parent / \"fawos\" / \"FAWOS\" / \"datasets\" / \"diabetes\"\n",
    "df_for_experimenting.to_csv(data_path_write / \"raw_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = \"readmit_30_days\"\n",
    "Y = df_for_experimenting.loc[:, target_variable]\n",
    "X = df_for_experimenting.drop(columns=[target_variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>payer_code</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>...</th>\n",
       "      <th>examide</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Referral</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Missing</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Missing</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Missing</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Missing</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              race  gender      age   weight admission_type_id  \\\n",
       "0        Caucasian  Female   [0-10)  Unknown             Other   \n",
       "1        Caucasian  Female  [10-20)  Unknown         Emergency   \n",
       "2  AfricanAmerican  Female  [20-30)  Unknown         Emergency   \n",
       "3        Caucasian    Male  [30-40)  Unknown         Emergency   \n",
       "4        Caucasian    Male  [40-50)  Unknown         Emergency   \n",
       "\n",
       "  discharge_disposition_id admission_source_id  time_in_hospital payer_code  \\\n",
       "0                    Other            Referral                 1    Unknown   \n",
       "1       Discharged to Home           Emergency                 3    Unknown   \n",
       "2       Discharged to Home           Emergency                 2    Unknown   \n",
       "3       Discharged to Home           Emergency                 2    Unknown   \n",
       "4       Discharged to Home           Emergency                 1    Unknown   \n",
       "\n",
       "  medical_specialty  ...  examide  citoglipton  insulin  glyburide-metformin  \\\n",
       "0             Other  ...       No           No       No                   No   \n",
       "1           Missing  ...       No           No       Up                   No   \n",
       "2           Missing  ...       No           No       No                   No   \n",
       "3           Missing  ...       No           No       Up                   No   \n",
       "4           Missing  ...       No           No   Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone metformin-rosiglitazone  \\\n",
       "0                   No                        No                      No   \n",
       "1                   No                        No                      No   \n",
       "2                   No                        No                      No   \n",
       "3                   No                        No                      No   \n",
       "4                   No                        No                      No   \n",
       "\n",
       "  metformin-pioglitazone change  diabetesMed  \n",
       "0                     No     No           No  \n",
       "1                     No     Ch          Yes  \n",
       "2                     No     No          Yes  \n",
       "3                     No     Ch          Yes  \n",
       "4                     No     Ch          Yes  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head() # sanity check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling - SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['race', 'gender', 'weight', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', \\\n",
    "'payer_code', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', \\\n",
    "'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', \\\n",
    "'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone','tolazamide', 'examide', 'citoglipton', 'insulin','glyburide-metformin', \\\n",
    "'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed']\n",
    "\n",
    "col_idx_mapping = zip(df_for_experimenting.columns, range(len(df_for_experimenting.columns)))\n",
    "col_idx_filtered = list(filter(lambda x: x[0] in categorical_features, col_idx_mapping))\n",
    "idx_filtered = list(map(lambda x: x[1], col_idx_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset samples per class Counter({False: 90406, True: 90406})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTENC(random_state=42, categorical_features=list(idx_filtered))\n",
    "X_res_before_onehot, Y_res = sm.fit_resample(X, Y)\n",
    "print(f'Resampled dataset samples per class {Counter(Y_res)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding for the categorical features\n",
    "X_res = pd.get_dummies(X_res_before_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 445\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "X_train_res_before_onehot, X_test_res_before_onehot, X_train_res, X_test_res, Y_train_res, Y_test_res = train_test_split(\n",
    "    X_res_before_onehot,\n",
    "    X_res,\n",
    "    Y_res,\n",
    "    test_size=0.20,\n",
    "    stratify=Y_res,\n",
    "    random_state=random_seed\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy score for the testing data: 0.8063764645081966\n",
      "The precision score for the testing data: 0.8016114982578397\n",
      "The recall score for the testing data: 0.8142904545957306\n",
      "The F1 score for the testing data: 0.8079012345679012\n",
      "The F2 score for the testing data: 0.8117226779571316\n",
      "The G mean score for the testing data: 0.8063376285859623\n",
      "The Demographic parity difference score for the testing data: 0.5564906431178059\n",
      "The Equalized odds difference score for the testing data: 0.800861784595085\n",
      "The Equal opportunity difference score for the testing data: 0.8142904545957306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr_res = LogisticRegression(solver='newton-cg')\n",
    "lr_res.fit(X_train_res, Y_train_res)\n",
    "\n",
    "# Predicting on the test data\n",
    "lr_pred_test_res = lr_res.predict(X_test_res)\n",
    "evaluate_model_performance(Y_test_res, lr_pred_test_res)\n",
    "evaluate_model_fairness(Y_test_res, lr_pred_test_res, X_test_res_before_onehot['race'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy score for the testing data: 0.82354802190668\n",
      "The precision score for the testing data: 0.8035908878625915\n",
      "The recall score for the testing data: 0.8564318106404158\n",
      "The F1 score for the testing data: 0.829170347763232\n",
      "The F2 score for the testing data: 0.8453149051845543\n",
      "The G mean score for the testing data: 0.8228912448342858\n",
      "The Demographic parity difference score for the testing data: 0.40160133531249487\n",
      "The Equalized odds difference score for the testing data: 0.5630566551212272\n",
      "The Equal opportunity difference score for the testing data: 0.8564318106404158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "tree_auto_balanced_res = DecisionTreeClassifier()\n",
    "tree_auto_balanced_res.fit(X_train_res, Y_train_res)\n",
    "\n",
    "# Predicting on the test data\n",
    "tree_pred_test_res = tree_auto_balanced_res.predict(X_test_res)\n",
    "evaluate_model_performance(Y_test_res, tree_pred_test_res)\n",
    "evaluate_model_fairness(Y_test_res, tree_pred_test_res, X_test_res_before_onehot['race'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy score for the testing data: 0.7650408801118094\n",
      "The precision score for the testing data: 0.9056971133496995\n",
      "The recall score for the testing data: 0.5916933967481474\n",
      "The F1 score for the testing data: 0.7157718682053855\n",
      "The F2 score for the testing data: 0.6357780392436507\n",
      "The G mean score for the testing data: 0.7451430723382838\n",
      "The Demographic parity difference score for the testing data: 0.3750042142881225\n",
      "The Equalized odds difference score for the testing data: 0.6238248391885205\n",
      "The Equal opportunity difference score for the testing data: 0.5916933967481474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "perceptron_res = Perceptron()\n",
    "perceptron_res.fit(X_train_res, Y_train_res)\n",
    "\n",
    "# Predicting on the test data\n",
    "perceptron_pred_test_res = perceptron_res.predict(X_test_res)\n",
    "evaluate_model_performance(Y_test_res, perceptron_pred_test_res)\n",
    "evaluate_model_fairness(Y_test_res, perceptron_pred_test_res, X_test_res_before_onehot['race'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (linear kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy score for the testing data: 0.6904225538285937\n",
      "The precision score for the testing data: 0.6270992507289705\n",
      "The recall score for the testing data: 0.9396084503926557\n",
      "The F1 score for the testing data: 0.7521859435528501\n",
      "The F2 score for the testing data: 0.8544472495750394\n",
      "The G mean score for the testing data: 0.6438863966483235\n",
      "The Demographic parity difference score for the testing data: 0.5483657281301697\n",
      "The Equalized odds difference score for the testing data: 0.6200931881906646\n",
      "The Equal opportunity difference score for the testing data: 0.9396084503926557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_res = LinearSVC()\n",
    "svm_res.fit(X_train_res, Y_train_res)\n",
    "\n",
    "# Predicting on the test data\n",
    "svm_pred_test_res = svm_res.predict(X_test_res)\n",
    "evaluate_model_performance(Y_test_res, svm_pred_test_res)\n",
    "evaluate_model_fairness(Y_test_res, svm_pred_test_res, X_test_res_before_onehot['race'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy score for the testing data: 0.6232243909889918\n",
      "The precision score for the testing data: 0.5736816002645065\n",
      "The recall score for the testing data: 0.9595730560778675\n",
      "The F1 score for the testing data: 0.7180665052662072\n",
      "The F2 score for the testing data: 0.8457878779015922\n",
      "The G mean score for the testing data: 0.5246696265427713\n",
      "The Demographic parity difference score for the testing data: 0.8608610633491791\n",
      "The Equalized odds difference score for the testing data: 0.9672810489856507\n",
      "The Equal opportunity difference score for the testing data: 0.9595730560778675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "nbc = GaussianNB()\n",
    "nbc.fit(X_train_res, Y_train_res)\n",
    "\n",
    "# Predicting on the test data\n",
    "nbc_pred_test_res = nbc.predict(X_test_res)\n",
    "evaluate_model_performance(Y_test_res, nbc_pred_test_res)\n",
    "evaluate_model_fairness(Y_test_res, nbc_pred_test_res, X_test_res_before_onehot['race'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_embedding = TSNE(n_components=2, learning_rate=50, init='random', perplexity=50).fit_transform(pd.get_dummies(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_embedding_oversampled_smotenc = TSNE(n_components=2, learning_rate=50, init='random', perplexity=50).fit_transform(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanya\\AppData\\Local\\Temp\\ipykernel_8936\\3415768930.py:6: UserWarning: The palette list has more values (16) than needed (2), which may not be intended.\n",
      "  sns.scatterplot(\n",
      "C:\\Users\\Tanya\\AppData\\Local\\Temp\\ipykernel_8936\\3415768930.py:16: UserWarning: The palette list has more values (16) than needed (2), which may not be intended.\n",
      "  sns.scatterplot(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = ['#F3DC1B', '#F37A3F', '#EC1DF3', '#27C4F1', '#00F37A', \"red\", \"blue\", \"purple\", 'green', 'yellow', 'pink', 'cyan', 'magenta', 'orange', 'grey', 'black']\n",
    "\n",
    "sns.set()\n",
    "_, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "sns.scatterplot(\n",
    "    ax=axes[0],\n",
    "    x=tsne_embedding[:, 0], y=tsne_embedding[:, 1],\n",
    "    hue=list(Y),\n",
    "    data=tsne_embedding,\n",
    "    legend=\"full\",\n",
    "    alpha=0.2,\n",
    "    palette=colors\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    ax=axes[1],\n",
    "    x=tsne_embedding_oversampled_smotenc[:, 0], y=tsne_embedding_oversampled_smotenc[:, 1],\n",
    "    hue=list(Y_res),\n",
    "    data=tsne_embedding_oversampled_smotenc,\n",
    "    legend=\"full\",\n",
    "    alpha=0.2,\n",
    "    palette=colors\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_umap = reducer.fit_transform(pd.get_dummies(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_umap_resampled = reducer.fit_transform(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.set()\n",
    "_, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "sns.scatterplot(\n",
    "    ax=axes[0],\n",
    "    x=embedding_umap[:, 0], y=embedding_umap[:, 1],\n",
    "    hue=list(Y),\n",
    "    data=embedding_umap,\n",
    "    legend=\"full\",\n",
    "    alpha=0.2\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    ax=axes[1],\n",
    "    x=embedding_umap_resampled[:, 0], y=embedding_umap_resampled[:, 1],\n",
    "    hue=list(Y_res),\n",
    "    data=embedding_umap_resampled,\n",
    "    legend=\"full\",\n",
    "    alpha=0.2\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, whiten=True) \n",
    "X_pca = pca.fit_transform(pd.get_dummies(X))\n",
    "X_resampled_pca = pca.fit_transform(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.set()\n",
    "_, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "sns.scatterplot(\n",
    "    ax=axes[0],\n",
    "    x=X_pca[:, 0], y=X_pca[:, 1],\n",
    "    hue=list(Y),\n",
    "    data=X_pca,\n",
    "    legend=\"full\",\n",
    "    alpha=0.2\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    ax=axes[1],\n",
    "    x=X_resampled_pca[:, 0], y=X_resampled_pca[:, 1],\n",
    "    hue=list(Y_res),\n",
    "    data=X_resampled_pca,\n",
    "    legend=\"full\",\n",
    "    alpha=0.2\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3, whiten=True) \n",
    "X_pca_3d = pca.fit_transform(pd.get_dummies(X))\n",
    "X_resampled_pca_3d = pca.fit_transform(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10, 7))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    " \n",
    "# Creating plot\n",
    "ax.scatter3D(X_pca_3d[:, 0], X_pca_3d[:, 1], X_pca_3d[:, 2])\n",
    "plt.title(\"simple 3D scatter plot\")\n",
    " \n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertools (should be cited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = hyp.reduce(x=X, reduce='IncrementalPCA', ndims=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne_double_reduced = hyp.reduce(x=X_reduced, reduce='TSNE', ndims=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\hypertools\\plot\\plot.py:508: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  kwargs[kwarg]=np.array(kwargs[kwarg])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hypertools.datageometry.DataGeometry at 0x1fd98876110>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp.plot(X_tsne_double_reduced, '.', hue=Y, save_path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tanya\\Desktop\\TANYA\\FMI\\Masters\\thesis\\src\\env\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:542: FutureWarning: Starting in v1.3, whiten='unit-variance' will be used by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hypertools.datageometry.DataGeometry at 0x1fd23269780>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp.plot(X_res, '.', hue=Y_res, reduce='FastICA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
