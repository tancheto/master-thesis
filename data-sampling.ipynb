{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(os.getcwd()).parent / \"data\" / \"dataset_diabetes\"\n",
    "df_init = pd.read_csv(data_path / \"data_analyzed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>readmitted</th>\n",
       "      <th>readmit_30_days</th>\n",
       "      <th>readmit_binary</th>\n",
       "      <th>diabetes_type</th>\n",
       "      <th>had_emergency</th>\n",
       "      <th>had_inpatient_days</th>\n",
       "      <th>had_outpatient_days</th>\n",
       "      <th>race_all</th>\n",
       "      <th>age_all</th>\n",
       "      <th>age_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>30 years or younger</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Referral</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Type 1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>30 years or younger</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt;30</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Type 1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>30 years or younger</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-60 years</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Type 1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-60 years</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender                  age  \\\n",
       "0       2278392      8222157        Caucasian  Female  30 years or younger   \n",
       "1        149190     55629189        Caucasian  Female  30 years or younger   \n",
       "2         64410     86047875  AfricanAmerican  Female  30 years or younger   \n",
       "3        500364     82442376        Caucasian    Male          30-60 years   \n",
       "4         16680     42519267        Caucasian    Male          30-60 years   \n",
       "\n",
       "    weight admission_type_id discharge_disposition_id admission_source_id  \\\n",
       "0  Unknown             Other                    Other            Referral   \n",
       "1  Unknown         Emergency       Discharged to Home           Emergency   \n",
       "2  Unknown         Emergency       Discharged to Home           Emergency   \n",
       "3  Unknown         Emergency       Discharged to Home           Emergency   \n",
       "4  Unknown         Emergency       Discharged to Home           Emergency   \n",
       "\n",
       "   time_in_hospital  ... readmitted readmit_30_days  readmit_binary  \\\n",
       "0                 1  ...         NO           False           False   \n",
       "1                 3  ...        >30           False            True   \n",
       "2                 2  ...         NO           False           False   \n",
       "3                 2  ...         NO           False           False   \n",
       "4                 1  ...         NO           False           False   \n",
       "\n",
       "   diabetes_type  had_emergency  had_inpatient_days  had_outpatient_days  \\\n",
       "0         Type 1          False               False                False   \n",
       "1         Type 1          False               False                False   \n",
       "2            NaN          False                True                 True   \n",
       "3         Type 1          False               False                False   \n",
       "4            NaN          False               False                False   \n",
       "\n",
       "          race_all  age_all age_numeric  \n",
       "0        Caucasian   [0-10)           0  \n",
       "1        Caucasian  [10-20)          10  \n",
       "2  AfricanAmerican  [20-30)          20  \n",
       "3        Caucasian  [30-40)          30  \n",
       "4        Caucasian  [40-50)          40  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove ids & columns used for the analysis & the ones with most missing values (weight, payer_code, medical_specialty attributes)\n",
    "columns_to_remove = ['encounter_id', 'patient_nbr', 'readmitted', 'readmit_binary', 'diabetes_type', \\\n",
    "    'had_emergency', 'had_inpatient_days', 'had_outpatient_days', 'race_all', 'age_all', 'age_numeric', \\\n",
    "    'weight', 'payer_code', 'medical_specialty']\n",
    "\n",
    "df = df_init.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = \"readmit_30_days\"\n",
    "sensitive_attribute = \"race\"\n",
    "\n",
    "Y = df.loc[:, target_variable]\n",
    "A = df.loc[:, sensitive_attribute]\n",
    "X = pd.get_dummies(df.drop(columns=[target_variable, sensitive_attribute]))\n",
    "\n",
    "X_A = pd.get_dummies(df.drop(columns=[target_variable]))\n",
    "X_Y = pd.get_dummies(df.drop(columns=[sensitive_attribute]))\n",
    "X_A_Y = pd.get_dummies(df)\n",
    "\n",
    "Y_A = df[target_variable].astype(str) + \"_\" + df[sensitive_attribute].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 445\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, A_train, A_test, \\\n",
    "X_A_train, X_A_test, X_Y_train, X_Y_test, X_A_Y_train, X_A_Y_test, \\\n",
    "Y_A_train, Y_A_test = train_test_split(\n",
    "    X, Y, A,\n",
    "    X_A, X_Y, X_A_Y,\n",
    "    Y_A,\n",
    "    test_size=0.20,\n",
    "    stratify=Y,\n",
    "    random_state=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random undersampling - target attribute, without sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dummy_sensitive_attribute(df):\n",
    "    filter_col = [col for col in df if col.startswith(sensitive_attribute)]\n",
    "    return df.drop(filter_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undummyfy_sensitive_attribute(df):\n",
    "    filter_col = [col for col in df if col.startswith(sensitive_attribute)]\n",
    "    dummy_A_df = df[filter_col]\n",
    "    A_df = dummy_A_df[dummy_A_df == 1].idxmax(axis=1)\n",
    "    return A_df.apply(lambda s: s.removeprefix('race_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset samples per class Counter({False: 9086, True: 9086})\n"
     ]
    }
   ],
   "source": [
    "rus_target_wos = RandomUnderSampler(random_state=123, sampling_strategy='not minority')\n",
    "X_A_train_res_target_wos, Y_train_res_target_wos = rus_target_wos.fit_resample(X_A_train, Y_train)\n",
    "print(f'Resampled dataset samples per class {Counter(Y_train_res_target_wos)}')\n",
    "\n",
    "# drop race columns (one-hot encoded)\n",
    "X_train_res_target_wos = drop_dummy_sensitive_attribute(X_A_train_res_target_wos)\n",
    "A_train_res_target_wos = undummyfy_sensitive_attribute(X_A_train_res_target_wos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random undersampling - target attribute, with sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset samples per class Counter({False: 9086, True: 9086})\n"
     ]
    }
   ],
   "source": [
    "rus_target_ws = RandomUnderSampler(random_state=123, sampling_strategy='not minority')\n",
    "X_A_train_res_target_ws, Y_train_res_target_ws = rus_target_ws.fit_resample(X_A_train, Y_train)\n",
    "print(f'Resampled dataset samples per class {Counter(Y_train_res_target_ws)}')\n",
    "\n",
    "A_train_res_target_ws = undummyfy_sensitive_attribute(X_A_train_res_target_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random undersampling - sensitive attribute, without sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset samples per sensitive attribute Counter({'AfricanAmerican': 1846, 'Caucasian': 1846, 'Other': 1846, 'Unknown': 1846})\n"
     ]
    }
   ],
   "source": [
    "rus_sensitive_wos = RandomUnderSampler(random_state=123, sampling_strategy='not minority')\n",
    "X_Y_train_res_sensitive_wos, A_train_res_sensitive_wos = rus_sensitive_wos.fit_resample(X_Y_train, A_train)\n",
    "print(f'Resampled dataset samples per sensitive attribute {Counter(A_train_res_sensitive_wos)}')\n",
    "\n",
    "X_train_res_sensitive_wos = X_Y_train_res_sensitive_wos.drop(columns=[target_variable])\n",
    "Y_train_res_sensitive_wos = X_Y_train_res_sensitive_wos[target_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random undersampling - sensitive attribute, with sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset samples per class Counter({'AfricanAmerican': 1846, 'Caucasian': 1846, 'Other': 1846, 'Unknown': 1846})\n"
     ]
    }
   ],
   "source": [
    "rus_sensitive_ws = RandomUnderSampler(random_state=123, sampling_strategy='not minority')\n",
    "X_A_Y_train_res_sensitive_ws, A_train_res_sensitive_ws = rus_sensitive_ws.fit_resample(X_A_Y_train, A_train)\n",
    "print(f'Resampled dataset samples per class {Counter(A_train_res_sensitive_ws)}')\n",
    "\n",
    "X_A_train_res_sensitive_ws = X_A_Y_train_res_sensitive_ws.drop(columns=[target_variable])\n",
    "Y_train_res_sensitive_ws = X_A_Y_train_res_sensitive_ws[target_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random undersampling - multivariate, without sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset samples per class Counter({'False_AfricanAmerican': 154, 'False_Caucasian': 154, 'False_Other': 154, 'False_Unknown': 154, 'True_AfricanAmerican': 154, 'True_Caucasian': 154, 'True_Other': 154, 'True_Unknown': 154})\n"
     ]
    }
   ],
   "source": [
    "rus_multiv_wos = RandomUnderSampler(random_state=123, sampling_strategy='not minority')\n",
    "X_Y_train_res_multiv_wos, Y_A_res_wos = rus_multiv_wos.fit_resample(X_Y_train, Y_A_train)\n",
    "print(f'Resampled dataset samples per class {Counter(Y_A_res_wos)}')\n",
    "\n",
    "X_train_res_multiv_wos = X_Y_train_res_multiv_wos.drop(columns=[target_variable])\n",
    "Y_train_res_multiv_wos = X_Y_train_res_multiv_wos[target_variable]\n",
    "A_train_res_multiv_wos = Y_A_res_wos.apply(lambda r: r.split('_')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random undersampling - multivariate, with sensitive attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset samples per class Counter({'False_AfricanAmerican': 154, 'False_Caucasian': 154, 'False_Other': 154, 'False_Unknown': 154, 'True_AfricanAmerican': 154, 'True_Caucasian': 154, 'True_Other': 154, 'True_Unknown': 154})\n"
     ]
    }
   ],
   "source": [
    "rus_multiv_ws = RandomUnderSampler(random_state=123, sampling_strategy='not minority')\n",
    "X_A_Y_train_res_multiv_ws, Y_A_res_ws = rus_multiv_ws.fit_resample(X_A_Y_train, Y_A_train)\n",
    "print(f'Resampled dataset samples per class {Counter(Y_A_res_ws)}')\n",
    "\n",
    "X_A_train_res_multiv_ws = X_A_Y_train_res_multiv_ws.drop(columns=[target_variable])\n",
    "Y_train_res_multiv_ws = X_A_Y_train_res_multiv_ws[target_variable]\n",
    "A_train_res_multiv_ws = Y_A_res_ws.apply(lambda r: r.split('_')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save datasets in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(data_path / \"clsf_data\" / \"X_test_split.csv\", index=False)\n",
    "Y_test.to_csv(data_path / \"clsf_data\" / \"Y_test_split.csv\", index=False)\n",
    "A_test.to_csv(data_path / \"clsf_data\" / \"A_test_split.csv\", index=False)\n",
    "X_A_test.to_csv(data_path / \"clsf_data\" / \"X_A_test_split.csv\", index=False)\n",
    "\n",
    "X_train.to_csv(data_path / \"clsf_data\" / \"X_train_split.csv\", index=False)\n",
    "Y_train.to_csv(data_path / \"clsf_data\" / \"Y_train_split.csv\", index=False)\n",
    "A_train.to_csv(data_path / \"clsf_data\" / \"A_train_split.csv\", index=False)\n",
    "X_A_train.to_csv(data_path / \"clsf_data\" / \"X_A_train_split.csv\", index=False)\n",
    "\n",
    "X_train_res_target_wos.to_csv(data_path / \"clsf_data\" / \"X_train_res_target_wos.csv\", index=False)\n",
    "Y_train_res_target_wos.to_csv(data_path / \"clsf_data\" / \"Y_train_res_target_wos.csv\", index=False)\n",
    "A_train_res_target_wos.to_csv(data_path / \"clsf_data\" / \"A_train_res_target_wos.csv\", index=False)\n",
    "\n",
    "X_A_train_res_target_ws.to_csv(data_path / \"clsf_data\" / \"X_A_train_res_target_ws.csv\", index=False)\n",
    "Y_train_res_target_ws.to_csv(data_path / \"clsf_data\" / \"Y_train_res_target_ws.csv\", index=False)\n",
    "A_train_res_target_ws.to_csv(data_path / \"clsf_data\" / \"A_train_res_target_ws.csv\", index=False)\n",
    "\n",
    "X_train_res_sensitive_wos.to_csv(data_path / \"clsf_data\" / \"X_train_res_sensitive_wos.csv\", index=False)\n",
    "Y_train_res_sensitive_wos.to_csv(data_path / \"clsf_data\" / \"Y_train_res_sensitive_wos.csv\", index=False)\n",
    "A_train_res_sensitive_wos.to_csv(data_path / \"clsf_data\" / \"A_train_res_sensitive_wos.csv\", index=False)\n",
    "\n",
    "X_A_train_res_sensitive_ws.to_csv(data_path / \"clsf_data\" / \"X_A_train_res_sensitive_ws.csv\", index=False)\n",
    "Y_train_res_sensitive_ws.to_csv(data_path / \"clsf_data\" / \"Y_train_res_sensitive_ws.csv\", index=False)\n",
    "A_train_res_sensitive_ws.to_csv(data_path / \"clsf_data\" / \"A_train_res_sensitive_ws.csv\", index=False)\n",
    "\n",
    "X_train_res_multiv_wos.to_csv(data_path / \"clsf_data\" / \"X_train_res_multiv_wos.csv\", index=False)\n",
    "Y_train_res_multiv_wos.to_csv(data_path / \"clsf_data\" / \"Y_train_res_multiv_wos.csv\", index=False)\n",
    "A_train_res_multiv_wos.to_csv(data_path / \"clsf_data\" / \"A_train_res_multiv_wos.csv\", index=False)\n",
    "\n",
    "X_A_train_res_multiv_ws.to_csv(data_path / \"clsf_data\" / \"X_A_train_res_multiv_ws.csv\", index=False)\n",
    "Y_train_res_multiv_ws.to_csv(data_path / \"clsf_data\" / \"Y_train_res_multiv_ws.csv\", index=False)\n",
    "A_train_res_multiv_ws.to_csv(data_path / \"clsf_data\" / \"A_train_res_multiv_ws.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
